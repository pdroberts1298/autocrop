from __future__ import print_function

import cv2
import copy
import math
import numpy as np
import os
import sys

# Detect OpenCV 2.x vs 3.x
from pkg_resources import parse_version
IS_OPENCV_2 = parse_version(cv2.__version__) < parse_version('3.0.0')

# Alias BoxPoints as this lives in a different place in OpenCV 2 and 3
if IS_OPENCV_2:
    BoxPoints = cv2.cv.BoxPoints
else:
    BoxPoints = cv2.boxPoints


# Detection settings
MAX_COVERAGE = .98

def thresholdImage(img, lowerThresh):#, ignoreMask):
    _, binary = cv2.threshold(img, lowerThresh, 255, cv2.THRESH_BINARY_INV) # THRESH_TOZERO_INV
    #binary = cv2.bitwise_and(ignoreMask, binary)

    # Prevent tiny outlier collections of pixels spoiling the rect fitting
    kernel = np.ones((5,5),np.uint8)
    binary = cv2.dilate(binary, kernel, iterations = 3)
    binary = cv2.erode(binary, kernel, iterations = 3)

    return binary

def findLargestContourRect(binary):
    largestRect = None
    largestArea = 0

    # Find external contours of all shapes
    if IS_OPENCV_2:
        contours,_ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    else:
        contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    for cnt in contours:
        area = cv2.contourArea(cnt)

        # Keep track of the largest area seen
        if area > largestArea:
            largestArea = area
            largestRect = cv2.minAreaRect(cnt)

    return largestRect, largestArea

def findNonZeroPixelsRect(binary):
    edges = copy.copy(binary)

    if IS_OPENCV_2:
        contours,_ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    else:
        contours, hierarchy = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    nonZero = cv2.findNonZero(edges)

    if nonZero is None:
        return None, 0, binary

    rect = cv2.minAreaRect(nonZero)

    area = rect[1][0] * rect[1][1]

    return rect, area

def normaliseRectRotation(rawRects):
    """
    Normalize rect orientation to have an angle between -45 and 45 degrees

    Rects generated by OpenCV are can be "portrait" with a near -90 angle and flipped height/width
    To combine and compare rects meaningfully, they need to all have the same orientation.
    """
    rects = []

    for rect in rawRects:
        center = rect[0]
        size = rect[1]
        angle = rect[2]

        if angle < -45:
            rect = (
                center,
                (size[1], size[0]),
                angle + 90
            )

        rects.append(rect)

    return rects

def medianRect(rects):
    if len(rects) == 0:
        return None

    rects = normaliseRectRotation(rects)

    # Sort rects by area
    rects.sort(key=lambda rect: rect[1][0] * rect[1][1])
    rotations=[]
    for r in rects:
        if r[2] > 45:
            rotations.append(r[2]-90)
        if r[2] < -45:
            rotations.append(r[2]+90)
        else:
            rotations.append(r[2])
    
    median = (
        (np.median([r[0][0] for r in rects]), np.median([r[0][1] for r in rects])),
        (np.median([r[1][0] for r in rects]), np.median([r[1][1] for r in rects])),
        np.median(rotations)
    )

    return median

def correctAspectRatio(rect, targetRatio = 1.5, maxDifference = 0.3):
    """
    Return an aspect-ratio corrected rect (and success flag)

    Args:
        rect (OpenCV RotatedRect struct)
        targetRatio (float): Ratio represented as the larger image dimension divided by the smaller one

    """
    # Indexes into the rect nested tuple
    CENTER = 0; SIZE = 1; ANGLE = 2
    X = 0; Y = 1;

    size = rect[SIZE]

    aspectRatio = max(size[X], size[Y]) / float(min(size[X], size[Y]))
    aspectError = targetRatio - aspectRatio

    # Factor out orientation to simplify logic below
    # This assumes the larger dimension as X
    if size[X] == max(size[X], size[Y]):
        rectWidth = size[X]
        rectHeight = size[Y]
        widthDim = X
        heightDim = Y
    else:
        rectHeight = size[X]
        rectWidth = size[Y]
        widthDim = Y
        heightDim = X

    # Only attempt to correct aspect ratio where the ROI is roughly right already
    # This prevents odd results for poor outline detection
    if abs(aspectError) > maxDifference:
        return rect, False

    # Shrink width if the ratio was too wide
    if aspectRatio > targetRatio:
        rectWidth = size[heightDim] * targetRatio

    # Shrink height if the ratio was too tall
    elif aspectRatio < targetRatio:
        rectHeight = size[widthDim] / targetRatio

    # Apply new width/height in the original orientation
    if widthDim == X:
        newSize = (rectWidth, rectHeight)
    else:
        newSize = (rectHeight, rectWidth)

    newRect = (rect[CENTER], newSize, rect[ANGLE])

    return newRect, True

def findExposureBounds(img, showOutputWindow=False):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Smooth out noise
    gray = cv2.bilateralFilter(gray, 11, 17, 17)

    # Maximise brightness range
    gray = cv2.equalizeHist(gray)

    # Create a mask to ignore the brightest spots
    # These are usually where there is no film covering the light source
    ##_, ignoreMask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)

    # Expand masked out area slightly to include adjacent edges
    ##kernel = np.ones((3,3),np.uint8)
    ##ignoreMask = cv2.dilate(ignoreMask, kernel, iterations = 3)

    # Create a mask to ignore areas of low saturation
    # When white balanced against the film stock, this is usually low saturation
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    hsv = cv2.GaussianBlur(hsv, (5,5), 0)

    satMask = cv2.inRange(hsv, (0, 0, 0), (255, 7, 255))

    # Combine saturation and brightness masks, then flip
    ##ignoreMask = cv2.bitwise_or(ignoreMask, satMask)
    ##ignoreMask = cv2.bitwise_not(ignoreMask)

    # Get min/max region of interest areas
    height, width, _  = img.shape
    maxArea = (height * MAX_COVERAGE)  * (width * MAX_COVERAGE)

    minCaptureArea = maxArea * .7

    #algos = [findNonZeroPixelsRect]
    algos = [findLargestContourRect]
    results = []

    for func in algos:
        upperThreshold = 300
        while upperThreshold > 100:
            binary = thresholdImage(gray, upperThreshold)#, ignoreMask)
            
            debugImg = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)
            rect, area = func(binary)

            # Stop once a valid result is returned
            if area <= minCaptureArea:
                break

            if area >= minCaptureArea:
                results.append(rect)
                upperThreshold -= 5

                # Draw in green for results that are collected
                debugLineColour = (0, 255, 0)

            else:
                upperThreshold += 5

                # Draw in red for areas that were too small
                debugLineColour = (0, 0, 255)

            if showOutputWindow:
                if rect is not None:
                    rectPoints = BoxPoints(rect)
                    rectPoints = np.int0(rectPoints)
                    cv2.drawContours(debugImg, [rectPoints], -1, debugLineColour, 3)

                # Draw threshold on debug output
                cv2.putText(
                    img=debugImg,
                    text='Threshold: ' + str(upperThreshold),
                    org=(20, 30),
                    fontFace=cv2.FONT_HERSHEY_PLAIN,
                    fontScale=2,
                    color=(0, 150, 255),
                    lineType=4
                )

                cv2.imshow('image', cv2.resize(debugImg, (0,0), fx=0.75, fy=0.75) )
                cv2.waitKey(1)
    
    return medianRect(results)


if __name__ == '__main__':

    import argparse

    parser = argparse.ArgumentParser(description='Find crop for film negative scan')

    parser.add_argument('files', nargs='+', help='Image files to perform detection on (JPG, PNG, etc)')

    args = parser.parse_args()

    hasDisplay = os.getenv('DISPLAY') != None

    for filename in args.files:
        if not os.path.exists(filename):
            print("ERROR:")
            print("Could not find file '%s'" % filename)
            sys.exit(5)

        # read image and convert to gray
        img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)

        cv2.imshow('image', cv2.resize(img, (0,0), fx=0.75, fy=0.75) )
        cv2.waitKey(0)

        rawRect = findExposureBounds(img, showOutputWindow=hasDisplay)
        print(rawRect)
        # Outputs for Lightroom
        cropLeft = 0
        cropRight = 1.0
        cropTop = 0
        cropBottom = 1.0
        rotation = 0

        if rawRect is not None:
            rect, aspectChanged = correctAspectRatio(rawRect)
            print(rect)
            boxWidth = abs(rect[1][0]-rect[0][0])
            boxHeight = abs(rect[1][1]-rect[0][1])

            box = np.int0(BoxPoints(rect))
            print(box)
            # Lightroom doesn't support rotation more than 45 degrees
            # The detected rect usually includes a 90 degree rotation for landscape images
            rotation = -rect[2]
            
            if rotation > 45:
                rotation -= 90
            elif rotation < -45:
                rotation +=90


            # Calculate crops in a format for Lightroom (0.0 to 1.0 for each edge)
            centerX = rect[0][0]
            centerY = rect[0][1]

            # Use the average distance from each side as the crop in Lightroom
            imgHeight, imgWidth, _  = img.shape

            top = []; left = []; right = []; bottom =[]
            
            for point in box:
                if point[0] > centerX:
                    right.append( point[0] )
                else:
                    left.append( point[0] )

                if point[1] > centerY:
                    bottom.append( point[1] )
                else:
                    top.append( point[1] )

            print("right",right)
            print("shape HW", img.shape)
            if max(left)<0:
                rltb=[min(right),max(left),min(bottom),max(top)]
                rltb=[float(v) for v in rltb]
                print(rltb)
                left=[imgWidth-(rltb[1])-rltb[0]]
                right=[rltb[1]+rltb[0]]
                bottom=[rltb[2]+rltb[3]]
                top=[-bottom[0]+imgHeight]
                print(left,right,bottom,top)



            cropLeft = (max(left)) / float(imgWidth)
            cropRight = (min(right)) / float(imgWidth)
            cropTop = (max(top)) / float(imgHeight)
            cropBottom = (min(bottom)) / float(imgHeight)
            

            # Draw original detected area
            rawBox = np.int0(BoxPoints(rawRect))
            cv2.drawContours(img, [rawBox], -1, (255, 0, 0), 1)

            # Draw adjusted aspect ratio area
            #cv2.drawContours(img, [box], -1, (0, 255, 0), 2)

            cv2.circle(img, (int(rect[0][0]), int(rect[0][1])), 3, (0, 255, 0), 3)
        

        # Write result to disk for Lightroom plugin to pick up
        cropData = [
            cropLeft ,
            cropRight,
            cropTop,
            cropBottom,
            rotation,
        ]

        for v in cropData:
            print(v)

        with open(filename + ".txt", 'w') as out:
            out.write("\r\n".join(str(x) for x in cropData))

        cv2.imwrite(filename + "-analysis.jpg", img)
